# Session 7 Assignment

This assignment is for training GPatasetT 141M model using shapspeare d
## Training Log
I


.6329669952393ms | token: 981.4854995553574/sec
Step 4968 | loss: 1.7823060750961304 | norm: 3.510718584060669 | lr: 6.005568114341121e-05 |dt: 2082.8449726104736ms | token: 983.270491530245/sec
Step 4969 | loss: 1.706817626953125 | norm: 3.398981809616089 | lr: 6.005225555857004e-05 |dt: 2019.8709964752197ms | token: 1013.9261386365104/sec
Step 4970 | loss: 2.0283775329589844 | norm: 3.9660401344299316 | lr: 6.004893870864803e-05 |dt: 2044.6062088012695ms | token: 1001.6598752288443/sec
Step 4971 | loss: 1.8036558628082275 | norm: 3.6896748542785645 | lr: 6.004573059498124e-05 |dt: 2010.162115097046ms | token: 1018.8233001800093/sec
Step 4972 | loss: 1.672619342803955 | norm: 3.5241122245788574 | lr: 6.004263121886191e-05 |dt: 1955.2440643310547ms | token: 1047.4395689832613/sec
Step 4973 | loss: 1.9477660655975342 | norm: 3.7129805088043213 | lr: 6.0039640581538415e-05 |dt: 1954.7357559204102ms | token: 1047.7119445925698/sec
Step 4974 | loss: 1.624281406402588 | norm: 3.420985460281372 | lr: 6.00367586842154e-05 |dt: 2162.3947620391846ms | token: 947.0981136065517/sec
Step 4975 | loss: 1.56947922706604 | norm: 3.611553430557251 | lr: 6.003398552805372e-05 |dt: 2273.336172103882ms | token: 900.8786404452702/sec
Step 4976 | loss: 1.799375295639038 | norm: 3.5416665077209473 | lr: 6.003132111417041e-05 |dt: 2277.662992477417ms | token: 899.1672634468139/sec
Step 4977 | loss: 1.701189637184143 | norm: 4.3653998374938965 | lr: 6.002876544363863e-05 |dt: 2103.8379669189453ms | token: 973.4589983653924/sec
Step 4978 | loss: 1.7732874155044556 | norm: 3.6393215656280518 | lr: 6.002631851748785e-05 |dt: 1979.8779487609863ms | token: 1034.4071973131702/sec
Step 4979 | loss: 1.6626721620559692 | norm: 3.3746068477630615 | lr: 6.002398033670371e-05 |dt: 1926.6140460968018ms | token: 1063.0048110305843/sec
Step 4980 | loss: 1.7549562454223633 | norm: 3.601444721221924 | lr: 6.002175090222797e-05 |dt: 1933.0039024353027ms | token: 1059.4908770850484/sec
Step 4981 | loss: 1.7544472217559814 | norm: 3.845362663269043 | lr: 6.0019630214958706e-05 |dt: 1979.6359539031982ms | token: 1034.5336454220333/sec
Step 4982 | loss: 1.5664725303649902 | norm: 3.4491875171661377 | lr: 6.0017618275750094e-05 |dt: 2061.955213546753ms | token: 993.2320481768619/sec
Step 4983 | loss: 1.5925159454345703 | norm: 3.47576642036438 | lr: 6.0015715085412556e-05 |dt: 1996.38032913208ms | token: 1025.8566316821812/sec
Step 4984 | loss: 1.6482734680175781 | norm: 3.4629123210906982 | lr: 6.0013920644712703e-05 |dt: 2075.051784515381ms | token: 986.9633207627642/sec
Step 4985 | loss: 1.610103964805603 | norm: 3.3432652950286865 | lr: 6.001223495437332e-05 |dt: 2039.6673679351807ms | token: 1004.0852896878253/sec
Step 4986 | loss: 1.7733566761016846 | norm: 3.6791274547576904 | lr: 6.001065801507342e-05 |dt: 1997.8680610656738ms | token: 1025.0927175379065/sec
Step 4987 | loss: 1.8042337894439697 | norm: 3.537233352661133 | lr: 6.000918982744816e-05 |dt: 2037.2869968414307ms | token: 1005.2584653881257/sec
Step 4988 | loss: 1.687668800354004 | norm: 3.779214382171631 | lr: 6.0007830392088983e-05 |dt: 2017.3687934875488ms | token: 1015.183741619943/sec
Step 4989 | loss: 1.5630865097045898 | norm: 3.365999221801758 | lr: 6.000657970954341e-05 |dt: 2008.6567401885986ms | token: 1019.5868507666011/sec
Step 4990 | loss: 1.6451432704925537 | norm: 3.4784297943115234 | lr: 6.000543778031524e-05 |dt: 2072.2169876098633ms | token: 988.31348852236/sec
Step 4991 | loss: 1.5650984048843384 | norm: 3.557929039001465 | lr: 6.000440460486446e-05 |dt: 2026.8731117248535ms | token: 1010.4233896798639/sec
Step 4992 | loss: 1.4715744256973267 | norm: 3.242326021194458 | lr: 6.000348018360719e-05 |dt: 2084.134101867676ms | token: 982.6622951779856/sec
Step 4993 | loss: 1.4520032405853271 | norm: 3.274052858352661 | lr: 6.0002664516915844e-05 |dt: 2240.2660846710205ms | token: 914.1771211970766/sec
Step 4994 | loss: 1.8171405792236328 | norm: 3.503051519393921 | lr: 6.000195760511895e-05 |dt: 2017.2672271728516ms | token: 1015.2348545662043/sec
Step 4995 | loss: 1.7155430316925049 | norm: 3.6376256942749023 | lr: 6.000135944850121e-05 |dt: 2062.8979206085205ms | token: 992.7781590840298/sec
Step 4996 | loss: 1.71785306930542 | norm: 3.3340578079223633 | lr: 6.000087004730361e-05 |dt: 2069.1330432891846ms | token: 989.7865227382428/sec
Step 4997 | loss: 1.9922236204147339 | norm: 3.8256211280822754 | lr: 6.0000489401723284e-05 |dt: 2031.7840576171875ms | token: 1007.9811347677519/sec
Step 4998 | loss: 1.9434260129928589 | norm: 3.5919859409332275 | lr: 6.0000217511913525e-05 |dt: 1996.980905532837ms | token: 1025.548113317363/sec
Step 4999 | loss: 1.8245803117752075 | norm: 3.363710880279541 | lr: 6.000005437798384e-05 |dt: 1995.964765548706ms | token: 1026.0702169444305/sec


## Gradio Link
https://huggingface.co/spaces/yeswantht/GPT




**Yeswanth**
